{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data function\n",
    "\n",
    "def read_bci_data():\n",
    "    S4b_test = np.load('S4b_test.npz')\n",
    "    X11b_test = np.load('X11b_test.npz')\n",
    "\n",
    "    test_data = np.concatenate((S4b_test['signal'], X11b_test['signal']), axis=0)\n",
    "    test_label = np.concatenate((S4b_test['label'], X11b_test['label']), axis=0)\n",
    "    test_label = test_label -1\n",
    "\n",
    "    test_data = np.transpose(np.expand_dims(test_data, axis=1), (0, 1, 3, 2))\n",
    "\n",
    "    mask = np.where(np.isnan(test_data))\n",
    "    test_data[mask] = np.nanmean(test_data)\n",
    "\n",
    "    print(test_data.shape, test_label.shape)\n",
    "\n",
    "    return test_data, test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EEGNet and DeepConvNet function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self,activation_name):\n",
    "        super(EEGNet, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding = (0,25),bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, eps=1e-5)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(16, 32, (2, 1),groups=16,bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32, eps=1e-5)\n",
    "        if activation_name=='relu':\n",
    "            self.act1=nn.ReLU()\n",
    "        elif activation_name=='leakyrelu':\n",
    "            self.act1=nn.LeakyReLU()\n",
    "        elif activation_name=='elu':\n",
    "            self.act1=nn.ELU()\n",
    "        self.pooling2 = nn.AvgPool2d((1, 4))\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv2d(32, 32, (1, 15),padding = (0,7),bias=False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(32, eps=1e-5)\n",
    "        if activation_name=='relu':\n",
    "            self.act2=nn.ReLU()\n",
    "        elif activation_name=='leakyrelu':\n",
    "            self.act2=nn.LeakyReLU()\n",
    "        elif activation_name=='elu':\n",
    "            self.act2=nn.ELU()\n",
    "        self.pooling3 = nn.AvgPool2d((1, 8))\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(736, 2,bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pooling2(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pooling3(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.view(-1, 736)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepConvNet(nn.Module):\n",
    "    def __init__(self,activation_name):\n",
    "        super(DeepConvNet, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 25, (1, 5))\n",
    "        self.conv2 = nn.Conv2d(25, 25, (2, 1))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(25, eps=1e-5)\n",
    "        if activation_name=='relu':\n",
    "            self.act1=nn.ReLU()\n",
    "        elif activation_name=='leakyrelu':\n",
    "            self.act1=nn.LeakyReLU()\n",
    "        elif activation_name=='elu':\n",
    "            self.act1=nn.ELU()\n",
    "        self.pooling1 = nn.MaxPool2d((1, 2))\n",
    "        self.drop1 = nn.Dropout(p=0.25)\n",
    "        \n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv3 = nn.Conv2d(25, 50, (1, 5))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(50, eps=1e-5)\n",
    "        if activation_name=='relu':\n",
    "            self.act2=nn.ReLU()\n",
    "        elif activation_name=='leakyrelu':\n",
    "            self.act2=nn.LeakyReLU()\n",
    "        elif activation_name=='elu':\n",
    "            self.act2=nn.ELU()\n",
    "        self.pooling2 = nn.MaxPool2d((1, 2))\n",
    "        self.drop2 = nn.Dropout(p=0.25)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv4 = nn.Conv2d(50, 100, (1, 5))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(100, eps=1e-5)\n",
    "        if activation_name=='relu':\n",
    "            self.act3=nn.ReLU()\n",
    "        elif activation_name=='leakyrelu':\n",
    "            self.act3=nn.LeakyReLU()\n",
    "        elif activation_name=='elu':\n",
    "            self.act3=nn.ELU()\n",
    "        self.pooling3 = nn.MaxPool2d((1, 2))\n",
    "        self.drop3 = nn.Dropout(p=0.25)\n",
    "        \n",
    "        # Layer 4\n",
    "        self.conv5 = nn.Conv2d(100, 200, (1, 5))\n",
    "        self.batchnorm4 = nn.BatchNorm2d(200, eps=1e-5)\n",
    "        if activation_name=='relu':\n",
    "            self.act4=nn.ReLU()\n",
    "        elif activation_name=='leakyrelu':\n",
    "            self.act4=nn.LeakyReLU()\n",
    "        elif activation_name=='elu':\n",
    "            self.act4=nn.ELU()\n",
    "        self.pooling4 = nn.MaxPool2d((1, 2))\n",
    "        self.drop4 = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8600, 2,bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pooling1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pooling2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.pooling3(x)\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        # Layer 4\n",
    "        x = self.conv5(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.pooling4(x)\n",
    "        x = self.drop4(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.view(-1, 8600)\n",
    "        x = F.softmax(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y):\n",
    "    results = []\n",
    "    batch_size = 72\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(15):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X[s:e])\n",
    "        inputs = Variable(inputs.to(device='cuda:0', dtype=torch.float))\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "    inputs = Variable(torch.from_numpy(X).to(device='cuda:0', dtype=torch.float))\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "            \n",
    "    acc=accuracy_score(Y, np.argmax(predicted,axis=-1))\n",
    "            \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_elu_net = EEGNet(\"elu\").cuda(0)\n",
    "eeg_relu_net = EEGNet(\"relu\").cuda(0)\n",
    "eeg_leakyrelu_net = EEGNet(\"leakyrelu\").cuda(0)\n",
    "deep_conv_elu_net = DeepConvNet(\"elu\").cuda(0)\n",
    "deep_conv_relu_net = DeepConvNet(\"relu\").cuda(0)\n",
    "deep_conv_leakyrelu_net = DeepConvNet(\"leakyrelu\").cuda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model structure</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 2, 750]             816\n",
      "       BatchNorm2d-2           [-1, 16, 2, 750]              32\n",
      "            Conv2d-3           [-1, 32, 1, 750]              64\n",
      "       BatchNorm2d-4           [-1, 32, 1, 750]              64\n",
      "               ELU-5           [-1, 32, 1, 750]               0\n",
      "         AvgPool2d-6           [-1, 32, 1, 187]               0\n",
      "           Dropout-7           [-1, 32, 1, 187]               0\n",
      "            Conv2d-8           [-1, 32, 1, 187]          15,360\n",
      "       BatchNorm2d-9           [-1, 32, 1, 187]              64\n",
      "              ELU-10           [-1, 32, 1, 187]               0\n",
      "        AvgPool2d-11            [-1, 32, 1, 23]               0\n",
      "          Dropout-12            [-1, 32, 1, 23]               0\n",
      "           Linear-13                    [-1, 2]           1,474\n",
      "================================================================\n",
      "Total params: 17,874\n",
      "Trainable params: 17,874\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.16\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 1.23\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 2, 750]             816\n",
      "       BatchNorm2d-2           [-1, 16, 2, 750]              32\n",
      "            Conv2d-3           [-1, 32, 1, 750]              64\n",
      "       BatchNorm2d-4           [-1, 32, 1, 750]              64\n",
      "              ReLU-5           [-1, 32, 1, 750]               0\n",
      "         AvgPool2d-6           [-1, 32, 1, 187]               0\n",
      "           Dropout-7           [-1, 32, 1, 187]               0\n",
      "            Conv2d-8           [-1, 32, 1, 187]          15,360\n",
      "       BatchNorm2d-9           [-1, 32, 1, 187]              64\n",
      "             ReLU-10           [-1, 32, 1, 187]               0\n",
      "        AvgPool2d-11            [-1, 32, 1, 23]               0\n",
      "          Dropout-12            [-1, 32, 1, 23]               0\n",
      "           Linear-13                    [-1, 2]           1,474\n",
      "================================================================\n",
      "Total params: 17,874\n",
      "Trainable params: 17,874\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.16\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 1.23\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 2, 750]             816\n",
      "       BatchNorm2d-2           [-1, 16, 2, 750]              32\n",
      "            Conv2d-3           [-1, 32, 1, 750]              64\n",
      "       BatchNorm2d-4           [-1, 32, 1, 750]              64\n",
      "         LeakyReLU-5           [-1, 32, 1, 750]               0\n",
      "         AvgPool2d-6           [-1, 32, 1, 187]               0\n",
      "           Dropout-7           [-1, 32, 1, 187]               0\n",
      "            Conv2d-8           [-1, 32, 1, 187]          15,360\n",
      "       BatchNorm2d-9           [-1, 32, 1, 187]              64\n",
      "        LeakyReLU-10           [-1, 32, 1, 187]               0\n",
      "        AvgPool2d-11            [-1, 32, 1, 23]               0\n",
      "          Dropout-12            [-1, 32, 1, 23]               0\n",
      "           Linear-13                    [-1, 2]           1,474\n",
      "================================================================\n",
      "Total params: 17,874\n",
      "Trainable params: 17,874\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.16\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 1.23\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 25, 2, 746]             150\n",
      "            Conv2d-2           [-1, 25, 1, 746]           1,275\n",
      "       BatchNorm2d-3           [-1, 25, 1, 746]              50\n",
      "               ELU-4           [-1, 25, 1, 746]               0\n",
      "         MaxPool2d-5           [-1, 25, 1, 373]               0\n",
      "           Dropout-6           [-1, 25, 1, 373]               0\n",
      "            Conv2d-7           [-1, 50, 1, 369]           6,300\n",
      "       BatchNorm2d-8           [-1, 50, 1, 369]             100\n",
      "               ELU-9           [-1, 50, 1, 369]               0\n",
      "        MaxPool2d-10           [-1, 50, 1, 184]               0\n",
      "          Dropout-11           [-1, 50, 1, 184]               0\n",
      "           Conv2d-12          [-1, 100, 1, 180]          25,100\n",
      "      BatchNorm2d-13          [-1, 100, 1, 180]             200\n",
      "              ELU-14          [-1, 100, 1, 180]               0\n",
      "        MaxPool2d-15           [-1, 100, 1, 90]               0\n",
      "          Dropout-16           [-1, 100, 1, 90]               0\n",
      "           Conv2d-17           [-1, 200, 1, 86]         100,200\n",
      "      BatchNorm2d-18           [-1, 200, 1, 86]             400\n",
      "              ELU-19           [-1, 200, 1, 86]               0\n",
      "        MaxPool2d-20           [-1, 200, 1, 43]               0\n",
      "          Dropout-21           [-1, 200, 1, 43]               0\n",
      "           Linear-22                    [-1, 2]          17,202\n",
      "================================================================\n",
      "Total params: 150,977\n",
      "Trainable params: 150,977\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.49\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 3.07\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 25, 2, 746]             150\n",
      "            Conv2d-2           [-1, 25, 1, 746]           1,275\n",
      "       BatchNorm2d-3           [-1, 25, 1, 746]              50\n",
      "              ReLU-4           [-1, 25, 1, 746]               0\n",
      "         MaxPool2d-5           [-1, 25, 1, 373]               0\n",
      "           Dropout-6           [-1, 25, 1, 373]               0\n",
      "            Conv2d-7           [-1, 50, 1, 369]           6,300\n",
      "       BatchNorm2d-8           [-1, 50, 1, 369]             100\n",
      "              ReLU-9           [-1, 50, 1, 369]               0\n",
      "        MaxPool2d-10           [-1, 50, 1, 184]               0\n",
      "          Dropout-11           [-1, 50, 1, 184]               0\n",
      "           Conv2d-12          [-1, 100, 1, 180]          25,100\n",
      "      BatchNorm2d-13          [-1, 100, 1, 180]             200\n",
      "             ReLU-14          [-1, 100, 1, 180]               0\n",
      "        MaxPool2d-15           [-1, 100, 1, 90]               0\n",
      "          Dropout-16           [-1, 100, 1, 90]               0\n",
      "           Conv2d-17           [-1, 200, 1, 86]         100,200\n",
      "      BatchNorm2d-18           [-1, 200, 1, 86]             400\n",
      "             ReLU-19           [-1, 200, 1, 86]               0\n",
      "        MaxPool2d-20           [-1, 200, 1, 43]               0\n",
      "          Dropout-21           [-1, 200, 1, 43]               0\n",
      "           Linear-22                    [-1, 2]          17,202\n",
      "================================================================\n",
      "Total params: 150,977\n",
      "Trainable params: 150,977\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.49\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 3.07\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 25, 2, 746]             150\n",
      "            Conv2d-2           [-1, 25, 1, 746]           1,275\n",
      "       BatchNorm2d-3           [-1, 25, 1, 746]              50\n",
      "         LeakyReLU-4           [-1, 25, 1, 746]               0\n",
      "         MaxPool2d-5           [-1, 25, 1, 373]               0\n",
      "           Dropout-6           [-1, 25, 1, 373]               0\n",
      "            Conv2d-7           [-1, 50, 1, 369]           6,300\n",
      "       BatchNorm2d-8           [-1, 50, 1, 369]             100\n",
      "         LeakyReLU-9           [-1, 50, 1, 369]               0\n",
      "        MaxPool2d-10           [-1, 50, 1, 184]               0\n",
      "          Dropout-11           [-1, 50, 1, 184]               0\n",
      "           Conv2d-12          [-1, 100, 1, 180]          25,100\n",
      "      BatchNorm2d-13          [-1, 100, 1, 180]             200\n",
      "        LeakyReLU-14          [-1, 100, 1, 180]               0\n",
      "        MaxPool2d-15           [-1, 100, 1, 90]               0\n",
      "          Dropout-16           [-1, 100, 1, 90]               0\n",
      "           Conv2d-17           [-1, 200, 1, 86]         100,200\n",
      "      BatchNorm2d-18           [-1, 200, 1, 86]             400\n",
      "        LeakyReLU-19           [-1, 200, 1, 86]               0\n",
      "        MaxPool2d-20           [-1, 200, 1, 43]               0\n",
      "          Dropout-21           [-1, 200, 1, 43]               0\n",
      "           Linear-22                    [-1, 2]          17,202\n",
      "================================================================\n",
      "Total params: 150,977\n",
      "Trainable params: 150,977\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.49\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 3.07\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:151: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(eeg_elu_net, (1, 2, 750))\n",
    "summary(eeg_relu_net, (1, 2, 750))\n",
    "summary(eeg_leakyrelu_net, (1, 2, 750))\n",
    "summary(deep_conv_elu_net, (1, 2, 750))\n",
    "summary(deep_conv_relu_net, (1, 2, 750))\n",
    "summary(deep_conv_leakyrelu_net, (1, 2, 750))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load pre-training model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepConvNet(\n",
       "  (conv1): Conv2d(1, 25, kernel_size=(1, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(25, 25, kernel_size=(2, 1), stride=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): LeakyReLU(negative_slope=0.01)\n",
       "  (pooling1): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.25, inplace=False)\n",
       "  (conv3): Conv2d(25, 50, kernel_size=(1, 5), stride=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): LeakyReLU(negative_slope=0.01)\n",
       "  (pooling2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop2): Dropout(p=0.25, inplace=False)\n",
       "  (conv4): Conv2d(50, 100, kernel_size=(1, 5), stride=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act3): LeakyReLU(negative_slope=0.01)\n",
       "  (pooling3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop3): Dropout(p=0.25, inplace=False)\n",
       "  (conv5): Conv2d(100, 200, kernel_size=(1, 5), stride=(1, 1))\n",
       "  (batchnorm4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act4): LeakyReLU(negative_slope=0.01)\n",
       "  (pooling4): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop4): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=8600, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_elu_model = torch.load('./model/eegnet_elu_8333.pt')\n",
    "eeg_relu_model = torch.load('./model/eegnet_relu_8638.pt')\n",
    "egg_leaky_model = torch.load('./model/eegnet_laekyrelu_8611.pt')\n",
    "deep_conv_elu_model = torch.load('./model/deepconvnet_elu_8703.pt')\n",
    "deep_conv_relu_model = torch.load('./model/deepconvnet_relu_875.pt')\n",
    "deep_conv_leakyrelu_model = torch.load('./model/deepconvnet_laekyrelu_8722.pt')\n",
    "eeg_elu_model.eval()\n",
    "eeg_relu_model.eval()\n",
    "egg_leaky_model.eval()\n",
    "deep_conv_elu_model.eval()\n",
    "deep_conv_relu_model.eval()\n",
    "deep_conv_leakyrelu_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1, 2, 750) (1080,)\n"
     ]
    }
   ],
   "source": [
    "test_data, test_label=read_bci_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of EEGNet on test set(ELU) :  83.8 %\n",
      "Accuracy of EEGNet on test set(ReLU) :  87.22 %\n",
      "Accuracy of EEGNet on test set(LeakyReLU) :  88.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:151: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DeepConvNet on test set(ELU) :  86.94 %\n",
      "Accuracy of DeepConvNet on test set(ReLU) :  87.87 %\n",
      "Accuracy of DeepConvNet on test set(LeakyReLU) :  87.87 %\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(eeg_elu_model, test_data, test_label)\n",
    "print(\"Accuracy of EEGNet on test set(ELU) : \",np.round(test_acc*100,2),\"%\")\n",
    "test_acc = evaluate(eeg_relu_model, test_data, test_label)\n",
    "print(\"Accuracy of EEGNet on test set(ReLU) : \",np.round(test_acc*100,2),\"%\")\n",
    "test_acc = evaluate(egg_leaky_model, test_data, test_label)\n",
    "print(\"Accuracy of EEGNet on test set(LeakyReLU) : \",np.round(test_acc*100,2),\"%\")\n",
    "test_acc = evaluate(deep_conv_elu_model, test_data, test_label)\n",
    "print(\"Accuracy of DeepConvNet on test set(ELU) : \",np.round(test_acc*100,2),\"%\")\n",
    "test_acc = evaluate(deep_conv_relu_model, test_data, test_label)\n",
    "print(\"Accuracy of DeepConvNet on test set(ReLU) : \",np.round(test_acc*100,2),\"%\")\n",
    "test_acc = evaluate(deep_conv_leakyrelu_model, test_data, test_label)\n",
    "print(\"Accuracy of DeepConvNet on test set(LeakyReLU) : \",np.round(test_acc*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
