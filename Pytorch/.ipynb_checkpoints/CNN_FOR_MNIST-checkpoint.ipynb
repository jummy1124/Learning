{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(SimpleCNN, self).__init__()  \n",
    "        self.conv1 = nn.Sequential( # (1,28,28)  \n",
    "                     nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5,  \n",
    "                               stride=1, padding=2), # (16,28,28)  \n",
    "        # 想要con2d卷積出來的圖片尺寸沒有變化, padding=(kernel_size-1)/2  1\n",
    "                     nn.ReLU(),  \n",
    "                     nn.MaxPool2d(kernel_size=2) # (16,14,14)  \n",
    "                     )  \n",
    "        self.conv2 = nn.Sequential( # (16,14,14)  \n",
    "                     nn.Conv2d(16, 32, 5, 1, 2), # (32,14,14)  \n",
    "                     nn.ReLU(),  \n",
    "                     nn.MaxPool2d(2) # (32,7,7)  \n",
    "                     )  \n",
    "        self.out = nn.Linear(32*7*7, 10)  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        x = self.conv1(x)  \n",
    "        x = self.conv2(x)  \n",
    "        x = x.view(x.size(0), -1) # 將（batch，32,7,7）展平為（batch，32*7*7）  \n",
    "        output = self.out(x)  \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 , loss : 1.0243 , acc : 67.3383\n",
      "epoch : 2 , loss : 0.2604 , acc : 89.4200\n",
      "epoch : 3 , loss : 0.1721 , acc : 92.6867\n",
      "epoch : 4 , loss : 0.1385 , acc : 94.0567\n",
      "epoch : 5 , loss : 0.1171 , acc : 94.9483\n",
      "epoch : 6 , loss : 0.1026 , acc : 95.4683\n",
      "epoch : 7 , loss : 0.0917 , acc : 96.0350\n",
      "epoch : 8 , loss : 0.0835 , acc : 96.3983\n",
      "epoch : 9 , loss : 0.0772 , acc : 96.6683\n",
      "epoch : 10 , loss : 0.0720 , acc : 96.8683\n",
      "epoch : 11 , loss : 0.0676 , acc : 97.0117\n",
      "epoch : 12 , loss : 0.0639 , acc : 97.1683\n",
      "epoch : 13 , loss : 0.0610 , acc : 97.3117\n",
      "epoch : 14 , loss : 0.0579 , acc : 97.4417\n",
      "epoch : 15 , loss : 0.0559 , acc : 97.5033\n",
      "epoch : 16 , loss : 0.0539 , acc : 97.6200\n",
      "epoch : 17 , loss : 0.0518 , acc : 97.7067\n",
      "epoch : 18 , loss : 0.0502 , acc : 97.7433\n",
      "epoch : 19 , loss : 0.0488 , acc : 97.8333\n",
      "epoch : 20 , loss : 0.0471 , acc : 97.9200\n"
     ]
    }
   ],
   "source": [
    "batch_size=300\n",
    "learning_rate=1e-2\n",
    "num_epoches=20\n",
    "\n",
    "data_tf=transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5],[0.5])])\n",
    "\n",
    "train_dataset=datasets.MNIST(root='./data',train=True,transform=data_tf,download=True)\n",
    "test_dataset=datasets.MNIST(root='./data',train=False,transform=data_tf)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model=SimpleCNN()\n",
    "if torch.cuda.is_available():\n",
    "    model=model.cuda()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print_loss=0\n",
    "    if torch.cuda.is_available():\n",
    "        for data in train_loader:\n",
    "            img,label=data\n",
    "            img=img.view(img.size(0),-1)\n",
    "            if torch.cuda.is_available():\n",
    "                img=Variable(img,volatile=True).cuda()\n",
    "                label=Variable(label,volatile=True).cuda()\n",
    "            else:\n",
    "                img=Variable(img,volatile=True)\n",
    "                label=Variable(label,volatile=True)\n",
    "                \n",
    "            \n",
    "            out=model(img.reshape(300,1,28,28))\n",
    "            loss=criterion(out,label)\n",
    "            print_loss+=loss.data.item()/label.size(0)\n",
    "            _, predict=torch.max(out.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predict == label).sum().item()\n",
    "            acc=100*correct / total\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print('epoch : {}'.format(epoch+1),', loss : {:.4f}'.format(print_loss),', acc : {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
